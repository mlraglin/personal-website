---
# An instance of the Experience widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: experience

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 40

title: Experience
subtitle:

# Date format for experience
#   Refer to https://wowchemy.com/docs/customization/#date-format
date_format: Jan 2006

# Experiences.
#   Add/remove as many `experience` items below as you like.
#   Required fields are `title`, `company`, and `date_start`.
#   Leave `date_end` empty if it's your current employer.
#   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
experience:
  - title: Assistant Coach
    company: Bloomington High School North Girls Varsity Swim Team
    location: Bloomington, Indiana
    date_start: '2020-10-01'
    date_end: '2021-03-01'
    description: Helped coach a team of over 30 high school girls on the varsity swim team at 4-8 practices a week. Led swimmers through various types of 2+ hour workout sets and attended swim meets, providing mental and emotional support to female athletes throughout their swimming and high school careers.

  - title: Software Development Intern
    company: Garyfallidis Research Group at Indiana University School of Informatics, Computing, and Engineering
    company_url: 'https://grg.sice.indiana.edu/'
    location: Bloomington, Indiana
    date_start: '2020-05-01'
    date_end: '2020-12-31'
    description: |2-
        Internship Experiences:

        * Wrote 3D visualization and animation tutorials in Python for new users of FURY, an international open-source scientific visualization project
        * Implemented new shapes and functions to expand the FURY library using 3-dimensional calculus and linear algebra concepts with the help of Python packages such as NumPy and VTK9
        * Used Git/GitHub heavily for making and editing pull requests


        Tools used:
        * Python (vtk9, numpy, pandas)
        * Git/GitHub

  - title: Research Assistant
    company: The Ohio State University Sociology Department
    location: Columbus, Ohio
    date_start: '2020-01-01'
    date_end: '2023-04-01'
    description: |2-
        Spring 2022 Experiences:
        * Presented facial recognition research and DCiFR GUI software at the Population Association of America 2022 conference in Atlanta, Georgia. The presentation was entitled "Computer Vision and Applications in Social Science: Deriving Race and Gender From Photos" in the "Machine Learning Applications to Population Processes" session.
        * Joined the openVA research group under Professor Sam Clark to begin working on projects related to demographic data, including building a relational database management system in SQLite for population data

        Spring 2021 Experiences:
        * Became confident in Python software development skills and researched PyQt packages to build a GUI connected to deep-learning facial analysis models
        * First author of DCiFR project, creating and refining features including single image mode and batch mode, check box selection of multiple attributes, output and error messages for the deep learning model analysis, and formatted CSV results.

        Spring 2020 Experiences:

        * Mastered web-scraping with Python and was able to experience the full process of data analysis, from collection and organization to statistical regression analysis
        * Learned about facial recognition software, sentiment analysis, and natural language processing
        * Became interested in the social applications of data analytics practices, influencing me to pick up a minor in sociology


        Tools used:
        * Python (pandas, numpy, pytorch, deepface, fairface)
        * R

  - title: Leadership Development Program Intern
    company: Abercrombie & Fitch Co.
    location: New Albany, Ohio
    date_start: '2022-06-06'
    date_end: '2022-08-03'
    description: |2-
        Internship experiences:
        * Worked on the data strategy team on personalization projects, using insights collection on customer data with Snowflake to develop strategies and hypotheses for A/B testing to implement new features and experiences for users across all channels (email, app, push, browser).
        * Optimized web analytics tag management database architecture, improving the method of storing neccessary metadata on tag data from hundreds of sources, including Google Analytics.
        * Completed both a final personal project and cross-functional case competition, presenting to a panel of judges of various levels across the company, utilizing both techincal and personal presentation skills.


        Tools used:
        * SQL
        * Snowflake
        * Adobe Analytics
        * PowerBI
        * Google Analytics
        * Excel

  - title: Data Consultant
    company: The Ohio State University Office of Advancement
    location: Columbus, Ohio
    date_start: '2023-01-09'
    date_end: '2023-03-14'
    description: |2-
        * Presented valuable customer segment insights to The Ohio State University's Office of Advancement.
        * Produced robust statistical insights and business strategies from raw data in R.

        Tools used:
        * Python
        * Jupyter Notebook
        * Canva

  - title: Data Consultant
    company: IGS Energy
    location: Columbus, Ohio
    date_start: '2023-03-16'
    date_end: '2023-05-02'
    description: |2-
        * Produced valuable predictive insights for IGS Energy Home Warranty Claims.
        * Built a predictive statistical model from raw data using Python, and presented relevant findings and suggestions to business stakeholders.

        Tools used:
        * R
        * RStudio
        * Canva

  - title: Data Analyst
    company: Chartmetric
    company_url: https://chartmetric.com/
    location: New York, New York
    date_start: '2023-10-16'
    description: |2-
        * Delivering high-impact ad hoc analyses daily using SQL for internal teams and external clients, informing business decisions, music industry research, marketing/social media, and more.
        * Creating, monitoring, and optimizing automated data pipelines on a daily basis using Python and Airflow to power external data shares and cutting-edge product developments with high-quality data.
        * Building informative and interactive dashboards for external clients, using internal dashboard technologies, as well as tools such as Looker.

        Tools used:
        * SQL
        * Python
        * Airflow
        * Snowflake / ClickHouse / RDS
        * Hex
        * Looker

design:
  columns: '2'
---
